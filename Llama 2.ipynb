{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0cecb79-a5ca-4a68-acd6-564a7f7fae2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing model response\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://10.173.18.85:1234/v1\",\n",
    "    api_key=\"lm-studio\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"llama-2-13b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Say hello in one short sentence.\"}],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a3aab58-a47e-46f2-8c66-08d1b2def986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Batch 1: rows 2 to 101 (pandas idx 1..100)\n",
      "ðŸ“„ Tweet 2/750 | ðŸ·ï¸ Not relevant | â±ï¸ 9.72s\n",
      "ðŸ“„ Tweet 3/750 | ðŸ·ï¸ Ageist | â±ï¸ 3.54s\n",
      "ðŸ“„ Tweet 4/750 | ðŸ·ï¸ Not relevant | â±ï¸ 4.48s\n",
      "ðŸ“„ Tweet 5/750 | ðŸ·ï¸ Age-positive | â±ï¸ 2.97s\n",
      "ðŸ“„ Tweet 6/750 | ðŸ·ï¸ Ageist | â±ï¸ 4.14s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 201\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found. Please rename your tweet text column to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 201\u001b[0m classification, reasoning, raw \u001b[38;5;241m=\u001b[39m classify_tweet(text)\n\u001b[1;32m    203\u001b[0m df\u001b[38;5;241m.\u001b[39mat[i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m classification\n\u001b[1;32m    204\u001b[0m df\u001b[38;5;241m.\u001b[39mat[i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m reasoning\n",
      "Cell \u001b[0;32mIn[4], line 157\u001b[0m, in \u001b[0;36mclassify_tweet\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mclassify_tweet\u001b[39m(text: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    155\u001b[0m     prompt_text \u001b[38;5;241m=\u001b[39m PROMPT_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(keywords_text\u001b[38;5;241m=\u001b[39mkeywords_text, text\u001b[38;5;241m=\u001b[39mtext \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 157\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    158\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[1;32m    159\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[{\n\u001b[1;32m    160\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    161\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt_text}]\n\u001b[1;32m    162\u001b[0m         }],\n\u001b[1;32m    163\u001b[0m         response_format\u001b[38;5;241m=\u001b[39mclassification_schema,\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    166\u001b[0m     raw \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(raw, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/openai/_utils/_utils.py:286\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py:1189\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m not_given,\n\u001b[1;32m   1187\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m   1188\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m-> 1189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m   1190\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1191\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[1;32m   1192\u001b[0m             {\n\u001b[1;32m   1193\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m   1194\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m   1195\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[1;32m   1196\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m   1197\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[1;32m   1198\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[1;32m   1199\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[1;32m   1200\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[1;32m   1201\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[1;32m   1202\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m   1203\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m   1204\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[1;32m   1205\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[1;32m   1206\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[1;32m   1207\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[1;32m   1208\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[1;32m   1209\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_cache_key\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt_cache_key,\n\u001b[1;32m   1210\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_cache_retention\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt_cache_retention,\n\u001b[1;32m   1211\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[1;32m   1212\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[1;32m   1213\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msafety_identifier\u001b[39m\u001b[38;5;124m\"\u001b[39m: safety_identifier,\n\u001b[1;32m   1214\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[1;32m   1215\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[1;32m   1216\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[1;32m   1217\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[1;32m   1218\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m   1219\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[1;32m   1220\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m   1221\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[1;32m   1222\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m   1223\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[1;32m   1224\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m   1225\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[1;32m   1226\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbosity\u001b[39m\u001b[38;5;124m\"\u001b[39m: verbosity,\n\u001b[1;32m   1227\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_search_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: web_search_options,\n\u001b[1;32m   1228\u001b[0m             },\n\u001b[1;32m   1229\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsStreaming\n\u001b[1;32m   1230\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[1;32m   1231\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsNonStreaming,\n\u001b[1;32m   1232\u001b[0m         ),\n\u001b[1;32m   1233\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m   1234\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m   1235\u001b[0m         ),\n\u001b[1;32m   1236\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[1;32m   1237\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1238\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[1;32m   1239\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/openai/_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1258\u001b[0m     )\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/openai/_base_client.py:982\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    980\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 982\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[1;32m    983\u001b[0m         request,\n\u001b[1;32m    984\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    986\u001b[0m     )\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    988\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[1;32m    915\u001b[0m     request,\n\u001b[1;32m    916\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[1;32m    917\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m    918\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m    919\u001b[0m )\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[1;32m    943\u001b[0m         request,\n\u001b[1;32m    944\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m    945\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[1;32m    946\u001b[0m     )\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mhandle_request(\n\u001b[1;32m    237\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[1;32m    238\u001b[0m     )\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    219\u001b[0m     )\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv(max_bytes)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from docx import Document\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "\n",
    "# -----------------------------\n",
    "# LLM Client Setup\n",
    "# -----------------------------\n",
    "client = OpenAI(\n",
    "    base_url=\"http://10.173.18.85:1234/v1\",\n",
    "    api_key=\"lm-studio\"\n",
    ")\n",
    "model_name = \"llama-2-13b\"\n",
    "\n",
    "# -----------------------------\n",
    "# File Paths\n",
    "# -----------------------------\n",
    "INPUT_FILE = \"750-tweets-without answer.xlsx\"\n",
    "OUTPUT_FILE = \"Llama2_zero-shot.xlsx\"\n",
    "KEYWORDS_DOCX = \"Keywords list_final.docx\"\n",
    "\n",
    "# -----------------------------\n",
    "# Batch settings\n",
    "# -----------------------------\n",
    "BATCH_SIZE = 100\n",
    "START_EXCEL_ROW = 2  # user request\n",
    "START_IDX = START_EXCEL_ROW - 1  # pandas index (row2 -> idx1)\n",
    "\n",
    "# -----------------------------\n",
    "# JSON Schema for classification\n",
    "# -----------------------------\n",
    "classification_schema = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"AgeismClassification\",\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"classification\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"Not relevant\", \"Ageist\", \"Age-positive\"]\n",
    "                },\n",
    "                \"reasoning\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Brief explanation justifying the classification decision\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"classification\", \"reasoning\"]\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Load keyword list\n",
    "# -----------------------------\n",
    "keywords_doc = Document(KEYWORDS_DOCX)\n",
    "keywords_text = \"\\n\".join([p.text for p in keywords_doc.paragraphs]).strip()\n",
    "\n",
    "# -----------------------------\n",
    "# Load input Excel file\n",
    "# -----------------------------\n",
    "df = pd.read_excel(INPUT_FILE, dtype=str)\n",
    "\n",
    "# Ensure needed columns exist\n",
    "if \"classification\" not in df.columns:\n",
    "    df[\"classification\"] = \"\"\n",
    "if \"reasoning\" not in df.columns:\n",
    "    df[\"reasoning\"] = \"\"\n",
    "\n",
    "# -----------------------------\n",
    "# Prompt template\n",
    "# -----------------------------\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert in social psychology and research on age beliefs. \n",
    "\n",
    "Our goal is to create 3 lists of tweets.  To create these 3 lists, first identify all tweets that describe an older person or older people in general using Keyword List A from the attached document.\n",
    "\n",
    "Once you have identified the tweets describing older persons, classify them into one of 3 categories: (1) ageist tweets using Keyword List B and the definition below; (2) age-positive tweets using Keyword List C and the corresponding definition below; or 3) not relevant tweets. \n",
    "\n",
    "The final dataset should include the following columns for each tweet: a single classification label (Ageist, Age-positive, or Not relevant) and reasoning explaining why the classification was made (e.g., â€œis ageist because uses age stereotype of frailtyâ€ or â€œis age-positive because praises older adults for resilienceâ€).\n",
    "\n",
    "Our definition of â€œageistâ€ tweets are tweets that are related to older persons and show an unfavorable portrayal and/or treatment of older persons.\n",
    "Our definition of â€œage-positiveâ€ tweets are those that are related to older persons and show the favorable portrayal and/or treatment of older persons.\n",
    "Our definition of â€œnot relevantâ€ tweets are those that are not related to older persons and/ or are related to older persons but describes them in a neutral way that is not ageist or age-positive.\n",
    "\n",
    "When analyzing and classifying tweets, explicitly pay close attention to sarcasm, humor, contextual ambiguity, cultural references, figurative language, and nuanced sentiment. Tweets may use irony, exaggeration, slang, or culturally specific expressions that change their meaning. Do not rely solely on keywords; always interpret the intended meaning within context before classifying.\n",
    "\n",
    "When classifying a tweet as related to older persons, please note the following rules. Please do not consider a tweet related to an older person when: \n",
    "(1) tweets describe old objects (e.g., â€œold car,â€ â€œold houseâ€) unless the term refers to an old body part (e.g., â€œold kneesâ€ or â€œold brainâ€). \n",
    "(2) â€œold,â€ refers to â€œold + testamentâ€ or old refers to something that is not an older person, like \"the old you,\" \"the old we,\" \"old time,\" \"old adage,\" or \"old outhouse\"  \n",
    "(3) â€œsenior(s)â€ refers to high school or college seniors. \n",
    "(4) â€œpopâ€ refers to soda, a verb, music, food (â€œpop tartâ€), or could refer to a younger person (e.g., â€œmy popâ€ could mean a young â€œdadâ€). \n",
    "(5) For â€œelderâ€ refers to Elder Scrolls (the video game). \n",
    "(6) For â€œgranny,â€ refers to granny smith which is an apple. \n",
    "(7) For â€œantiqueâ€ and â€œancient,â€ describes objects rather than people. \n",
    "(8) For â€œnursing home,â€ â€œassisted living,â€ or â€œcare home,â€ does not refer to older persons.\n",
    "(9) the keyword â€œelderâ€ is only referring to someone who is older than someone else, such as an â€œelder sibling,â€  but is not referring to an older person.\n",
    "\n",
    "In addition to the rules listed above, please apply the following clarification rules:\n",
    "(1) Tweets that mention dementia, Alzheimerâ€™s disease, memory loss, cognitive decline, or similar conditions may be classified as ageist, even if the tone appears sympathetic. This because the stereotype that all older persons develop dementia is a common negative age stereotype \n",
    "(2) Tweets that portray an older adult in a negative, mocking, complaining, or burdensome way (such as criticizing their cooking, speech, driving, abilities, slowness, confusion, or behavior) should be classified as ageist, even if the tweet is casual or humorous. For example, â€œmy grandmaâ€™s cooking smells terribleâ€ or â€œgrandpa wonâ€™t stop repeating himselfâ€ are ageist.\n",
    "(3) Tweets that express positive affection, respect, gratitude, pride, love, or admiration for an older adult should be classified as age-positive, including when someone says they miss or cherish an older relative who has passed away. This type of emotional remembrance about older persons counts as age-positive.\n",
    "(4) Tweets that describe celebrating an older person, including celebrating a birthday, should be counted as age-positive.\n",
    "(5) The word â€œretiredâ€ should only be coded as aging-related when it describes a person retiring due to age, not when it is used jokingly (e.g., â€œIâ€™m retired from datingâ€).\n",
    "(6) The term â€œmiddle-agedâ€ does not count as older adulthood and should not be classified as aging-related.\n",
    "(7) When terms like â€œgrandma,â€ â€œgrandpa,â€ or â€œold manâ€ are used metaphorically to describe the speakerâ€™s behavior in an ambiguous way (e.g., staying in and going to bed early), code as not relevant; However, if is clear the behavior is thought of in a negative way, code as ageist. \n",
    "(8) tweets that infantilize older persons or treat them like babies or small children should be labeled as ageist.\n",
    "\n",
    "Also, please see the correct classifications of the following 8 tweets that could assist as you decide how to classify tweets: \n",
    "1. \"Everybody grumpy today\"\n",
    "   - Keywords: \"grumpy\" (negative age stereotype)\n",
    "   - Classification: Not relevant to ageist or age-positive list (as it does not specifically refer to older persons)\n",
    " \n",
    "2. \"Y'all clamoring for the days of the Old Testament y'all would be slaves in those days\"\n",
    "   - Keywords: \"Old Testament\" (irrelevant as it refers to the Bible, not older people)\n",
    "   - Classification: Not relevant to ageist or age-positive list\n",
    " \n",
    "3. \"I lost my granny early in life but I cherish the moments I had with her forever\"\n",
    "   - Keywords: \"granny\"\n",
    "   - Classification: Age-positive (demonstrates value and positive memory of an older person)\n",
    "  \n",
    "4. \"WHAT?! You missed Grandparents Storytime last week? Guess what? You have a chance to catch it again on Saturday, March 21, at 10:30 a.m. Miss Tracey will sing songs, have craft time and share wonderful stories forâ€¦\"\n",
    "   - Keywords: \"Grandparents\"\n",
    "   - Classification: Age-positive (promotes engagement and positive role of grandparents)\n",
    " \n",
    "5. \"@captaintommoore has died from #COVID19. The 100-year-old helped raise almost Â£33m ($57M Cdn.) for the NHS. He was knighted last year. The Army veteran won the hearts of millions by walking 100 laps in his garden before his 100th birthday last April. #Hero #Positivity #Smile\"\n",
    "   - Keywords: \"100-year-old\", \"Hero\", \"Positivity\"\n",
    "   - Classification: Age-positive (highlights achievements and positive contributions of an older person)\n",
    " \n",
    "6. \"@Hichestan7 @SecPompeo @mikepompeo Still drinking from Trumpâ€™s septic tank? Its not good for you. The lies & bullshit eat away at your brain, accelerating dementia.\"\n",
    "   - Keywords: \"dementia\" (negative age stereotype)\n",
    "   - Classification: Ageist (uses dementia derogatorily)\n",
    " \n",
    "7. \"My old man bladder is so thankful! Not a lot more stressful than worrying if you can hold it the whole movie or not!\"\n",
    "   - Keywords: \"old man bladder\" (negative age reference)\n",
    "   - Classification: Ageist (implies bladder problem due to old age in a negative way)\n",
    " \n",
    "8. \"Hawk Nation tune-in Sun, 4/19 on #Knightline as Coach Derek Smith (@chowan6464) discusses the recent UCF verbal commitment by Hawks speedy senior WR @davismallinger1 Live from 10-11:00 am with coachâ€™s segment airing 10:20 am. ESPN Orlando 580 AM Hosted by @AP_Knightline https://t.co/yVmMX2jTyn\"\n",
    "   - Keywords: \"senior\"\n",
    "   - Classification: Not relevant to ageist or age-positive list (senior refers to high school senior, not older person)\n",
    "\n",
    "9.  â€œI pop up on ya block.â€\n",
    "  - Keywords: \"pop\"\n",
    " - Classification: Not relevant because pop used as a verb so tweet not about an older person. \n",
    "\n",
    "Keyword list:\n",
    "{keywords_text}\n",
    "\n",
    "Post:\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "def classify_tweet(text: str):\n",
    "    prompt_text = PROMPT_TEMPLATE.format(keywords_text=keywords_text, text=text or \"\")\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": prompt_text}]\n",
    "        }],\n",
    "        response_format=classification_schema,\n",
    "    )\n",
    "\n",
    "    raw = response.choices[0].message.content\n",
    "    if isinstance(raw, str):\n",
    "        raw = raw.strip()\n",
    "\n",
    "    try:\n",
    "        parsed = json.loads(raw) if isinstance(raw, str) else raw\n",
    "        classification = parsed.get(\"classification\", \"Not relevant\")\n",
    "        reasoning = parsed.get(\"reasoning\", \"\")\n",
    "    except Exception:\n",
    "        classification = \"Not relevant\"\n",
    "        reasoning = \"\"\n",
    "\n",
    "    return classification, reasoning, raw\n",
    "\n",
    "# -----------------------------\n",
    "# Batch loop: 100 per batch, start at row 2\n",
    "# -----------------------------\n",
    "n = len(df)\n",
    "if START_IDX >= n:\n",
    "    raise ValueError(f\"START_EXCEL_ROW={START_EXCEL_ROW} is beyond the dataset (n={n}).\")\n",
    "\n",
    "batch_start = START_IDX\n",
    "batch_num = 1\n",
    "\n",
    "while batch_start < n:\n",
    "    batch_end = min(batch_start + BATCH_SIZE, n)\n",
    "    print(f\"\\nðŸš€ Batch {batch_num}: rows {batch_start+1} to {batch_end} (pandas idx {batch_start}..{batch_end-1})\")\n",
    "\n",
    "    for i in range(batch_start, batch_end):\n",
    "        start_time = time.time()\n",
    "\n",
    "        text = df.at[i, \"text\"] if \"text\" in df.columns else None\n",
    "        if text is None:\n",
    "            raise KeyError(\"Column 'text' not found. Please rename your tweet text column to 'text'.\")\n",
    "\n",
    "        classification, reasoning, raw = classify_tweet(text)\n",
    "\n",
    "        df.at[i, \"classification\"] = classification\n",
    "        df.at[i, \"reasoning\"] = reasoning\n",
    "\n",
    "        print(f\"ðŸ“„ Tweet {i+1}/{n} | ðŸ·ï¸ {classification} | â±ï¸ {round(time.time()-start_time, 2)}s\")\n",
    "\n",
    "    # Save after each batch (safer)\n",
    "    df.to_excel(OUTPUT_FILE, index=False)\n",
    "    print(f\"âœ… Saved progress to {OUTPUT_FILE}\")\n",
    "\n",
    "    batch_start = batch_end\n",
    "    batch_num += 1\n",
    "\n",
    "print(f\"\\nðŸŽ‰ All done. Final saved to {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a228389-09ce-411c-ab6c-9e9d3f06d1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================\n",
      "Accuracy: 32.53%\n",
      "Correct predictions: 244 / 750\n",
      "====================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# Load files\n",
    "# -----------------------------\n",
    "pred_df = pd.read_excel(\"Llama2_zero-shot.xlsx\")\n",
    "ans_df  = pd.read_excel(\"750-tweets-answer.xlsx\")\n",
    "\n",
    "# Column names\n",
    "pred_col = \"classification\"\n",
    "aging_col = \"aging related (yes/ no)\"\n",
    "ageist_col = \"ageist (yes/ no)\"\n",
    "pos_col = \"age positive (yes/ no)\"\n",
    "\n",
    "# -----------------------------\n",
    "# Step 1: Create gold label using your rules\n",
    "# -----------------------------\n",
    "def create_gold_label(row):\n",
    "    aging = row[aging_col].strip().upper()\n",
    "    ageist = row[ageist_col].strip().upper()\n",
    "    agepos = row[pos_col].strip().upper()\n",
    "\n",
    "    if aging == \"Y\" and ageist == \"Y\":\n",
    "        return \"Ageist\"\n",
    "    elif aging == \"Y\" and agepos == \"Y\":\n",
    "        return \"Age-positive\"\n",
    "    else:\n",
    "        return \"Not relevant\"\n",
    "\n",
    "ans_df[\"gold_label\"] = ans_df.apply(create_gold_label, axis=1)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2: Clean predicted label formatting\n",
    "# -----------------------------\n",
    "pred_df[\"pred_label\"] = (\n",
    "    pred_df[pred_col]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.replace(\"-\", \"\", regex=False)\n",
    "    .str.title()\n",
    ")\n",
    "\n",
    "pred_df[\"pred_label\"] = pred_df[\"pred_label\"].replace({\n",
    "    \"Agepositive\": \"Age-positive\",\n",
    "    \"Ageist\": \"Ageist\",\n",
    "    \"Not Relevant\": \"Not relevant\",\n",
    "})\n",
    "\n",
    "# -----------------------------\n",
    "# Step 3: Add gold_label next to pred_label\n",
    "# -----------------------------\n",
    "pred_df[\"gold_label\"] = ans_df[\"gold_label\"].values\n",
    "\n",
    "# Reorder columns so gold_label is right next to pred_label\n",
    "cols = list(pred_df.columns)\n",
    "pred_idx = cols.index(\"pred_label\")\n",
    "cols.insert(pred_idx + 1, cols.pop(cols.index(\"gold_label\")))\n",
    "pred_df = pred_df[cols]\n",
    "\n",
    "# -----------------------------\n",
    "# Step 4: Compare predicted vs gold\n",
    "# -----------------------------\n",
    "pred_df[\"correct\"] = pred_df[\"pred_label\"] == pred_df[\"gold_label\"]\n",
    "\n",
    "accuracy = pred_df[\"correct\"].mean()\n",
    "\n",
    "print(\"\\n====================================\")\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n",
    "print(f\"Correct predictions: {pred_df['correct'].sum()} / {len(pred_df)}\")\n",
    "print(\"====================================\\n\")\n",
    "\n",
    "# Save output\n",
    "pred_df.to_excel(\"Llama2_accuracy_output.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44aa4b31-27df-454d-88c8-b9eda2bac6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified: 506 / 750\n",
      "âœ… Misclassified tweets saved to: Llama2_misclassified.docx\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "\n",
    "# -----------------------------\n",
    "# Extract misclassified tweets\n",
    "# -----------------------------\n",
    "\n",
    "mis_df = pred_df.loc[~pred_df[\"correct\"]].copy()\n",
    "mis_df[\"gold_label\"] = ans_df.loc[~pred_df[\"correct\"], \"gold_label\"].values\n",
    "\n",
    "print(f\"Misclassified: {len(mis_df)} / {len(pred_df)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Save misclassified tweets to a Word document\n",
    "# -----------------------------\n",
    "DOCX_FILE = \"Llama2_misclassified.docx\"\n",
    "\n",
    "doc = Document()\n",
    "doc.add_heading(\"Misclassified Tweets\", level=1)\n",
    "doc.add_paragraph(f\"Total tweets: {len(pred_df)}\")\n",
    "doc.add_paragraph(f\"Misclassified: {len(mis_df)}\")\n",
    "doc.add_paragraph(f\"Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Helpful: include columns if they exist\n",
    "text_col = \"text\" if \"text\" in mis_df.columns else None\n",
    "\n",
    "for idx, r in mis_df.reset_index(drop=False).iterrows():\n",
    "    doc.add_heading(f\"Case {idx+1}\", level=2)\n",
    "\n",
    "    # tweet id/index (if useful)\n",
    "    if \"index\" in r:\n",
    "        doc.add_paragraph(f\"Row index: {r['index']}\")\n",
    "\n",
    "    # tweet text\n",
    "    if text_col:\n",
    "        doc.add_paragraph(\"Tweet:\", style=None)\n",
    "        doc.add_paragraph(str(r[text_col]))\n",
    "\n",
    "    # labels\n",
    "    doc.add_paragraph(f\"Predicted: {r['pred_label']}\")\n",
    "    doc.add_paragraph(f\"Gold: {r['gold_label']}\")\n",
    "\n",
    "    doc.add_paragraph(\"-\" * 40)\n",
    "\n",
    "doc.save(DOCX_FILE)\n",
    "print(f\"âœ… Misclassified tweets saved to: {DOCX_FILE}\")\n",
    "\n",
    "# (Optional) also save the misclassified subset to Excel/CSV\n",
    "mis_df.to_excel(\"Llama2_misclassified.xlsx\", index=False)\n",
    "mis_df.to_csv(\"Llama2_misclassified.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13750062-5427-49ce-9a96-756aa90633c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
